{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246303ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece6be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import PyPDF2\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baeae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e288623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272d744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the job titles and their corresponding labels\n",
    "job_titles = ['Data Scientist', 'Software Engineer', 'Marketing Manager']\n",
    "labels = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeaa66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a resume text into a BERT-compatible format\n",
    "def encode_resume(resume_text):\n",
    "    input_ids = torch.tensor(tokenizer.encode(resume_text, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs[0]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69756e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a resume based on its job title\n",
    "def classify_resume(resume_text):\n",
    "    logits = encode_resume(resume_text)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    top_prob, top_label = probs.max(1)\n",
    "    predicted_label = job_titles[top_label.item()]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4e0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb926cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3400f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = open('resume\\PU.pdf', 'rb') #resume input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3824c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = PyPDF2.PdfReader(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea19790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Author': 'Prateek Kala',\n",
       " '/Creator': 'MicrosoftÂ® Word 2016',\n",
       " '/CreationDate': \"D:20221205042833+00'00'\",\n",
       " '/Producer': 'www.ilovepdf.com',\n",
       " '/ModDate': 'D:20221205042833Z'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfReader.metadata #About PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96a50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in the document: 1\n"
     ]
    }
   ],
   "source": [
    "x= (len(pdfReader.pages))\n",
    "print(\"Number of pages in the document:\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38e927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3615a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number in range(x):\n",
    "    pdfReader = PyPDF2.PdfReader(pdf)\n",
    "    if pdfReader.is_encrypted:\n",
    "        pdfReader.decrypt('')\n",
    "    page = pdfReader.pages[page_number]\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f86f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close() # closing the pdf file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4f54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe9a4df",
   "metadata": {},
   "source": [
    "## Pre-Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b18b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('http\\S+\\s*', ' ', text)  # remove URLs\n",
    "text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
    "text = re.sub('#\\S+', '', text)  # remove hashtags\n",
    "text = re.sub('@\\S+', '  ', text)  # remove mentions\n",
    "text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)  # remove punctuation\n",
    "text = re.sub(r'[0-9]+', '', text)\n",
    "text = re.sub(r'[^\\x00-\\x7f]',r' ', text) \n",
    "text = re.sub('\\s+', ' ', text)  # remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47b8bc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CAREER OBJECTIVE Training and Certifications Jobs and Responsibilities COMPUTER SKILLS ACADEMIC BACKGROUND PRASHANT UPADHYAY Phone Email prashantupadhyay Prashant is a career oriented professional with decent communication and interpersonal skills who knows how to make sense of data and translate it into actionable insights He is familiar with gathering cleaning and organizing data for the use of technical and non technical personnel He is seeking a challenging position in a growth oriented organization w here he can effectively contribute through his skills and abilities Certifications Institution Google May Certificate Google Data analytics professional certification Institution LinkedIn Jul Certificate Tableau Essential Training Zummit Infolabs Nov Present Jr Data Scientist Writing code in Python Tensorflow Keras projects related to CNN GAN and RNN for the Hospitality or Financial domain Used Jupyter Collab notebooks for Machine Learning Deep Learning problems Yoshops com Jun Aug Data Science Intern Undertook to process structured and unstructured data and analyze large amounts of information to discover trends and patterns Combined models through ensemble modeling Present information using data visualization techniques with the help of Plotly Seaborn and Matplotlib Web Scraping using Python EDA on real time data Implementing the GPT model for auto generating text Handling Large Real world Datasets and Creating exe files from Python scripting Variedaperture com Dec Nov WordPress Developer Blogger Owner Designed and manipulated the website front end with the help of front end languages such as HTML JavaScript and CSS CISPL Global Gurgaon Mar Aug Jr US IT Recruiter Prepared weekly reports on recruiting activities candidate placements and job openings Handled the tasks of screening selecting and submitting candidates to job orders within a defined discipline Software Tableau Public Jupyter Notebook MySQL Microsoft Excel Microsoft word Kaggle Languages Python C C R programming SQL B TECH Computer Science Engineering with specialization in Mainframe technologies University of Petroleum and Energy Studies Dehradun JULY '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bf254ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted job title: Data Scientist\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# resume_text = \"John Doe is a highly skilled data scientist with 5 years of experience in the field. He has a PhD in Computer Science and has worked on several data-driven projects. John has strong programming skills in Python and is proficient in using data visualization tools such as Matplotlib and Seaborn. He is also familiar with machine learning algorithms and has experience working with large datasets.\"\n",
    "predicted_label = classify_resume(text)\n",
    "print(\"Predicted job title:\", predicted_label)  # Output: Predicted job title: Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90949bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a913a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb1f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534d0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369eae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2c7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd9ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
